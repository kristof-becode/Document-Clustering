{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Analysis using NLTK\n",
    "\n",
    "Solving an NLP problem is a multi-stage process. We need to clean the unstructured text data first before we can even think about getting to the modeling stage. Cleaning the data consists of a few key steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenization  \n",
    "\n",
    "Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.** Tokenization is the very first step in text analysis. \n",
    "\n",
    "* **Sentence tokenization**: split a document or paragraph into sentences\n",
    "sentence tokenization uses a pre-trained model from nltk_data/tokenizers/punkt/english.pickle.You can also specify other languages. The NLTK data package includes a pre-trained Punkt tokenizer for\n",
    "English.Punkt knows that the period in Mr. Smith does not mark sentence boundaries and sometimes sentences can start with non-capitalized words\n",
    "\n",
    "* **Word tokenization** :  split a sentence into tokens or words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hi Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, and city is awesome.',\n",
       " 'The sky is pinkish-blue.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = \"Hi Mr. Smith, how are you doing today? The weather is great, and city is awesome. The sky is pinkish-blue.\"\n",
    "\n",
    "tokenized_text = sent_tokenize(text)\n",
    "\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hallo meneer Smith, hoe gaat het vandaag met u?',\n",
       " 'Het weer is geweldig, en de stad is geweldig.',\n",
       " 'De lucht is roze-blauw.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18 languages supported\n",
    "text_dutch = u'''Hallo meneer Smith, hoe gaat het vandaag met u? Het weer is geweldig, en de stad is geweldig.\n",
    "De lucht is roze-blauw.'''\n",
    "\n",
    "tokenized_dutch = sent_tokenize(text_dutch, language='dutch')\n",
    "tokenized_dutch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Hi Mr. Smith, how are you doing today?\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution  \n",
    "\n",
    "It shows the number of occurances of a word in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Mr.': 2, 'Smith': 2, 'you': 2, 'Hi': 1, ',': 1, 'how': 1, 'are': 1, 'doing': 1, 'today': 1, '?': 1, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "text = \"Hi Mr. Smith, how are you doing today? Good to see you Mr. Smith.\"\n",
    "\n",
    "tokenized_word = word_tokenize(text)\n",
    "\n",
    "fdist = FreqDist(tokenized_word)\n",
    "\n",
    "display(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common: [('Mr.', 2), ('Smith', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common:\", fdist.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fdist.plot(10, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords  \n",
    "Stopwords considered as noise in the text. Text may contain stop words such as is, am, are, this, a, an, the, etc.\n",
    "In NLTK for removing stopwords, you need to create a list of stopwords and filter out your list of tokens from these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hi', 'Mr.', 'Smith', ',', 'today', '?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "## you can make a list of your stopwords that want to exclude or use the list from the library\n",
    "# wordslist = ['so', 'are', 'not']\n",
    "# stop_words = set(wordslist)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stop_words\n",
    "\n",
    "text = \"Hi Mr. Smith, how are you doing today?\"\n",
    "\n",
    "tokenized_word = word_tokenize(text)\n",
    "\n",
    "tokenized_word\n",
    "\n",
    "filtered_list =[]\n",
    "for word in tokenized_word:\n",
    "    if word not in stop_words:\n",
    "        filtered_list.append(word)\n",
    "        \n",
    "display(filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-Punctuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Mr', 'Smith', 'how', 'are', 'you', 'doing', 'today']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "text = \"Hi Mr. Smith, how are you doing today?\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon Normalization  \n",
    "\n",
    "Lexicon normalization considers another type of noise in the text. For example, connection, connected, connecting word reduce to a common word \"connect\". It reduces derivationally related forms of a word to a common root word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stemming \n",
    "Stemming is a process of linguistic normalization, which reduces words to their word root word or chops off the derivational affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do\n",
      "give\n",
      "care\n",
      "chocol\n",
      "fli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = ['doing', 'giving', 'caring', 'chocolates', 'flying']\n",
    "\n",
    "for word in words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lemmatization  \n",
    "Lemmatization reduces words to their base word, which is linguistically correct lemmas. It transforms root word with the use of vocabulary and morphological analysis. Lemmatization is usually more sophisticated than stemming. Stemmer works on an individual word without knowledge of the context. For example, The word \"better\" has \"good\" as its lemma. This thing will miss by stemming because it requires a dictionary look-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fli'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "stem = PorterStemmer()\n",
    "\n",
    "word = 'flying'\n",
    "\n",
    "lemmatized_word = lem.lemmatize(word, 'v')\n",
    "stemmed_word = stem.stem(word)\n",
    "display(lemmatized_word)\n",
    "display(stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "The primary target of Part-of-Speech(POS) tagging is to identify the grammatical group of a given word. Whether it is a NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. based on the context. POS Tagging looks for relationships within the sentence and assigns a corresponding tag to the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NNP'),\n",
       " ('Smith', 'NNP'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('doing', 'VBG'),\n",
       " ('today', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "sent = 'Mr. Smith, how are you doing today?'\n",
    "\n",
    "tokens = word_tokenize(sent)\n",
    "\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"Picture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Entity Recognition  \n",
    "Named-entity recognition is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    804\u001b[0m                     ]\n\u001b[0;32m    805\u001b[0m                     + \"-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}\".format(\n\u001b[1;32m--> 806\u001b[1;33m                         \u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m                     ).split()\n\u001b[0;32m    808\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1205\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Donald', 'NNP')]), Tree('PERSON', [('Trump', 'NNP')]), ('lives', 'VBZ'), ('in', 'IN'), ('the', 'DT'), Tree('FACILITY', [('White', 'NNP'), ('House', 'NNP')])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "\n",
    "text_ne = \"Donald Trump lives in the White House\"\n",
    "\n",
    "tokens = word_tokenize(text_ne)\n",
    "\n",
    "tags = nltk.pos_tag(tokens)\n",
    "\n",
    "chunks = ne_chunk(tags)\n",
    "display(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching text  \n",
    "There are many ways to examine the context of a text apart from simply reading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('gutenberg')\n",
    "# nltk.download('genesis')\n",
    "# nltk.download('inaugural')\n",
    "# nltk.download('nps_chat')\n",
    "# nltk.download('webtext')\n",
    "# nltk.download('treebank')\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "\n",
    "A concordance view shows us every occurrence of a given word, together with some context. For example, we saw that monstrous occurred in contexts such as the _ pictures and a _ size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar\n",
    "\n",
    "What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Contexts \n",
    "The term common_contexts allows us to examine just the contexts that are shared by two or more words, such as monstrous and very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.common_contexts(['monstrous', 'very'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion Plot\n",
    "\n",
    "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.draw.dispersion import dispersion_plot\n",
    "\n",
    "dispersion_plot(text2, ['monstrous', 'pretty', 'affection'])\n",
    "\n",
    "print('Total number of characters:', (len(text2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141576"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r'C:\\Users\\Personal\\Desktop\\TechTalk-text mining\\tkamb.txt','rU')\n",
    "raw=f.read()\n",
    "tokens = word_tokenize(raw)\n",
    "text_mb = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_plot(text_mb, ['Maycomb', 'town', 'detachment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations and N-grams\n",
    "\n",
    "A collocation is a sequence of words that occur together unusually often. Thus red wine is a collocation, whereas the wine is not. A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example, maroon wine sounds definitely odd.\n",
    "\n",
    "To get a handle on collocations, we start off by extracting from a text a list of word pairs, also known as bigrams. This is easily accomplished with the function bigrams():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "text = 'I am glad to see you'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "tokens\n",
    "\n",
    "list(ngrams(tokens, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
